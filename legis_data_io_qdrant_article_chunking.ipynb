{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings  # You can use other embedding models as well\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "from qdrant_client import QdrantClient\n",
    "import openai\n",
    "from qdrant_client.http import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\") \n",
    "input_dir = os.path.join(\"data\") \n",
    "inserted_doc_file_path = \"Introduction-to-Machine-Learning.docx\"\n",
    "inserted_doc_path = os.path.join(input_dir, inserted_doc_file_path)\n",
    "inserted_doc_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_doc_with_langchain(file_path):\n",
    "    loader = UnstructuredWordDocumentLoader(file_path,mode=\"elements\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # The content of the file is in the 'page_content' attribute of the first (and usually only) document\n",
    "    return documents\n",
    "\n",
    "# Usage example\n",
    "doc_content = load_doc_with_langchain(inserted_doc_path)\n",
    "print(doc_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict_list = []\n",
    "# exclude the first 6 pages of the document\n",
    "is_before_page_6 = True\n",
    "for i in range(len(doc_content)):\n",
    "    current_element = doc_content[i].dict()\n",
    "    if is_before_page_6:\n",
    "        if \"6\" == current_element[\"page_content\"]:\n",
    "            is_before_page_6 = False\n",
    "        else:\n",
    "            continue\n",
    "    current_element[\"metadata\"][\"element_id\"] = i\n",
    "    doc_dict_list.append(current_element)\n",
    "\n",
    "print(doc_dict_list[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign page numbers to the elements\n",
    "last_page = 0\n",
    "for element in doc_dict_list:\n",
    "    # check if the element is a number\n",
    "    if re.match(r\"^\\d+$\", element[\"page_content\"]):\n",
    "        last_page = int(element[\"page_content\"])\n",
    "        # delete the page number from the content\n",
    "        element[\"page_content\"] = \"\"\n",
    "    if last_page != 0:\n",
    "        element[\"metadata\"][\"page_number\"] = last_page\n",
    "\n",
    "# remove empty elements\n",
    "doc_dict_list = [element for element in doc_dict_list if element[\"page_content\"] != \"\"]\n",
    "print(doc_dict_list[:41])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [element for element in doc_dict_list if element[\"metadata\"][\"category\"] == \"Title\"]\n",
    "part_titles = [element for element in titles if \"Part\" in element[\"page_content\"]]\n",
    "chapter_titles = [element for element in titles if \"Chapter\" in element[\"page_content\"]]\n",
    "sub_titles = [element for element in titles if element not in part_titles and element not in chapter_titles]\n",
    "\n",
    "non_title_elements = [element for element in doc_dict_list if element not in titles]\n",
    "\n",
    "previous_part = part_titles[0]\n",
    "previous_chapter = chapter_titles[0]\n",
    "previous_sub_title = sub_titles[0]\n",
    "\n",
    "for element in doc_dict_list:\n",
    "    # assign the previous part to the element\n",
    "    if element in part_titles:\n",
    "        previous_part = element\n",
    "    elif element in chapter_titles:\n",
    "        previous_chapter = element\n",
    "    elif element in sub_titles:\n",
    "        previous_sub_title = element\n",
    "    else:\n",
    "        element[\"metadata\"][\"part\"] = previous_part[\"page_content\"]\n",
    "        element[\"metadata\"][\"chapter\"] = previous_chapter[\"page_content\"]\n",
    "        if element[\"metadata\"][\"element_id\"] > previous_sub_title[\"metadata\"][\"element_id\"] and previous_sub_title[\"metadata\"][\"element_id\"] > previous_chapter[\"metadata\"][\"element_id\"]:\n",
    "            element[\"metadata\"][\"sub_title\"] = previous_sub_title[\"page_content\"]\n",
    "        else:\n",
    "            element[\"metadata\"][\"sub_title\"] = \"\"\n",
    "\n",
    "\n",
    "non_title_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edited_elements = []\n",
    "# if the element has the same part, chapter and sub_title as the previous element, add the page_content to the previous element\n",
    "previous_element_id = -1\n",
    "for element in non_title_elements:\n",
    "    edited_element = element.copy()\n",
    "    if previous_element_id != -1 and element[\"metadata\"][\"part\"] == edited_elements[previous_element_id][\"metadata\"][\"part\"] \\\n",
    "        and element[\"metadata\"][\"chapter\"] == edited_elements[previous_element_id][\"metadata\"][\"chapter\"] \\\n",
    "        and element[\"metadata\"][\"sub_title\"] == edited_elements[previous_element_id][\"metadata\"][\"sub_title\"] \\\n",
    "        and len(edited_elements[previous_element_id][\"page_content\"]) < 1500:\n",
    "        edited_elements[previous_element_id][\"page_content\"] += f\" {element['page_content']}\" \n",
    "    else:\n",
    "#         edited_element[\"page_content\"] = f\"\"\"{edited_element[\"metadata\"][\"part\"]}\n",
    "# {edited_element[\"metadata\"][\"chapter\"]}\n",
    "# {edited_element[\"metadata\"][\"sub_title\"]} \n",
    "# {edited_element[\"page_content\"]}\n",
    "# \"\"\"\n",
    "        edited_elements.append(edited_element)\n",
    "        previous_element_id += 1\n",
    "\n",
    "edited_elements[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(edited_elements))\n",
    "print(edited_elements[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the size of the longest element\n",
    "# print the longest element\n",
    "longest_element = max(edited_elements, key=lambda x: len(x[\"page_content\"]))\n",
    "print(longest_element[\"page_content\"])\n",
    "print(len(longest_element[\"page_content\"]))\n",
    "\n",
    "\n",
    "# print the shortest element\n",
    "shortest_element = min(edited_elements, key=lambda x: len(x[\"page_content\"]))\n",
    "print(shortest_element[\"page_content\"])\n",
    "print(len(shortest_element[\"page_content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=os.environ[\"QDRANT_URL\"], \n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai_client = openai.Client(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "embedding_model_name = \"text-embedding-3-small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "collection_name = \"machine_learning_course_doc\"\n",
    "\n",
    "# Create a new collection (if it doesn't exist)\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into Qdrant\n",
    "for idx, item in tqdm(enumerate(edited_elements), total=len(edited_elements)):\n",
    "    # Get embedding for the text\n",
    "    embedding = openai_client.embeddings.create(input=item[\"page_content\"], model=embedding_model_name)\n",
    "    \n",
    "    # Create a point to insert\n",
    "    point = models.PointStruct(\n",
    "        id=idx,\n",
    "        vector=embedding.data[0].embedding,\n",
    "        payload={\n",
    "            \"page_content\": item[\"page_content\"],\n",
    "            \"metadata\": {\n",
    "                \"page_number\": item[\"metadata\"][\"page_number\"],\n",
    "                \"part\": item[\"metadata\"][\"part\"],\n",
    "                \"chapter\": item[\"metadata\"][\"chapter\"],\n",
    "                \"sub_title\": item[\"metadata\"][\"sub_title\"],\n",
    "                \"filename\": item[\"metadata\"][\"filename\"],\n",
    "                \"element_id\": item[\"metadata\"][\"element_id\"],\n",
    "                \"page_number\": item[\"metadata\"][\"page_number\"]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    # Insert the point into the collection\n",
    "    qdrant_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[point]\n",
    "    )\n",
    "\n",
    "print(\"Data inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import Qdrant\n",
    "\n",
    "retriever = Qdrant(\n",
    "    client=qdrant_client, \n",
    "    collection_name=collection_name,\n",
    "    embeddings= OpenAIEmbeddings(model=embedding_model_name),\n",
    ").as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(query=\"What are the types of machine learning?\", collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
